import os
import requests

os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

from huggingface_hub import hf_hub_download
from pathlib import Path
from huggingface_hub import snapshot_download
from huggingface_hub.utils import HfFolder

# è®¾ç½®å›½å†…é•œåƒ
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

def download_specific_file(repo_id, filename, save_path):
    """ä¸‹è½½æ•°æ®é›†ä»“åº“ä¸­çš„ç‰¹å®šæ–‡ä»¶"""
    os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
    try:
        file_path = hf_hub_download(
            repo_id=repo_id,
            filename=filename,
            local_dir=save_path,
            revision='main'
        )
        print(f"æ–‡ä»¶å·²ä¸‹è½½åˆ°: {file_path}")
        return file_path
    except Exception as e:
        print(f"ä¸‹è½½æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return None


def download_file_from_hf(url, save_path):
    # å°† blob æ›¿æ¢ä¸º resolve
    download_url = url.replace('/blob/', '/resolve/')
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    resp = requests.get(download_url, stream=True)
    resp.raise_for_status()
    with open(save_path, 'wb') as f:
        for chunk in resp.iter_content(chunk_size=8192):
            f.write(chunk)
    print(f"æ–‡ä»¶å·²ä¸‹è½½åˆ°: {save_path}")

def check_model_exists(model_id: str, token: str = None):
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨"""
    try:
        from huggingface_hub import model_info
        info = model_info(model_id, token=token)
        print(f"âœ… æ¨¡å‹å­˜åœ¨: {model_id}")
        print(f"ğŸ“ æ¨¡å‹ä¿¡æ¯: {info.modelId}")
        return True
    except Exception as e:
        print(f"âŒ æ¨¡å‹æ£€æŸ¥å¤±è´¥: {str(e)}")
        return False

def test_connection():
    """æµ‹è¯•ç½‘ç»œè¿æ¥"""
    import requests
    try:
        response = requests.get("https://hf-mirror.com", timeout=10)
        if response.status_code == 200:
            print("âœ… ç½‘ç»œè¿æ¥æ­£å¸¸")
            return True
        else:
            print(f"âŒ ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼ŒçŠ¶æ€ç : {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ ç½‘ç»œè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def clear_cache(model_id: str = None):
    """æ¸…ç†Hugging Faceç¼“å­˜"""
    try:
        from huggingface_hub import scan_cache_dir
        cache_info = scan_cache_dir()
        
        if model_id:
            # åˆ é™¤ç‰¹å®šæ¨¡å‹çš„ç¼“å­˜
            for repo in cache_info.repos:
                if model_id in repo.repo_id:
                    print(f"ğŸ—‘ï¸ æ¸…ç†æ¨¡å‹ç¼“å­˜: {repo.repo_id}")
                    repo.delete()
        else:
            print(f"ğŸ“ ç¼“å­˜ç›®å½•: {cache_info.size_on_disk_str}")
            print("æç¤º: å¯ä»¥æ‰‹åŠ¨åˆ é™¤ç¼“å­˜ç›®å½•æ¥æ¸…ç†æ‰€æœ‰ç¼“å­˜")
            
    except Exception as e:
        print(f"âš ï¸ ç¼“å­˜æ¸…ç†å¤±è´¥: {str(e)}")

def download_model_weights(
    model_id: str,
    local_dir: str = None,
    token: str = None,
    allow_patterns: list = None,
    ignore_patterns: list = None,
    force_download: bool = False
):
    """
    ä»Hugging Face Hubä¸‹è½½æ¨¡å‹æƒé‡
    
    å‚æ•°:
        model_id (str): æ¨¡å‹IDï¼Œæ ¼å¼ä¸º "username/model-name"
        local_dir (str): æœ¬åœ°ä¿å­˜ç›®å½•ï¼Œé»˜è®¤ä¸º "./models/{model_name}"
        token (str): Hugging Faceè®¿é—®ä»¤ç‰Œï¼ˆå¦‚æœéœ€è¦ï¼‰
        allow_patterns (list): å…è®¸ä¸‹è½½çš„æ–‡ä»¶æ¨¡å¼åˆ—è¡¨
        ignore_patterns (list): å¿½ç•¥ä¸‹è½½çš„æ–‡ä»¶æ¨¡å¼åˆ—è¡¨
        force_download (bool): æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
    """
    
    print("ğŸ” å¼€å§‹è¯Šæ–­...")
    
    # 1. æµ‹è¯•ç½‘ç»œè¿æ¥
    if not test_connection():
        print("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•")
        return None
    
    # 2. æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    if not check_model_exists(model_id, token):
        print("è¯·æ£€æŸ¥æ¨¡å‹IDæ˜¯å¦æ­£ç¡®ï¼Œæˆ–è€…æ˜¯å¦éœ€è¦ç™»å½•token")
        return None

    # è®¾ç½®é»˜è®¤ä¿å­˜ç›®å½•
    if local_dir is None:
        model_name = model_id.split('/')[-1]
        local_dir = f"./models/{model_name}"
    
    # åˆ›å»ºç›®å½•
    Path(local_dir).mkdir(parents=True, exist_ok=True)
    
    print(f"å¼€å§‹ä¸‹è½½æ¨¡å‹: {model_id}")
    print(f"ä¿å­˜è·¯å¾„: {os.path.abspath(local_dir)}")
    
    try:
        # ä¸‹è½½æ•´ä¸ªæ¨¡å‹ä»“åº“
        downloaded_path = snapshot_download(
            repo_id=model_id,
            local_dir=local_dir,
            token=token,
            allow_patterns=allow_patterns,
            ignore_patterns=ignore_patterns,
            force_download=force_download,
            resume_download=True  # æ”¯æŒæ–­ç‚¹ç»­ä¼ 
        )
        
        print(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
        print(f"ğŸ“ æ–‡ä»¶ä¿å­˜åœ¨: {downloaded_path}")
        
        # æ˜¾ç¤ºä¸‹è½½çš„æ–‡ä»¶åˆ—è¡¨
        print("\nğŸ“‹ ä¸‹è½½çš„æ–‡ä»¶:")
        for root, dirs, files in os.walk(downloaded_path):
            level = root.replace(downloaded_path, '').count(os.sep)
            indent = ' ' * 2 * level
            print(f"{indent}{os.path.basename(root)}/")
            subindent = ' ' * 2 * (level + 1)
            for file in files:
                file_path = os.path.join(root, file)
                file_size = os.path.getsize(file_path)
                size_mb = file_size / (1024 * 1024)
                print(f"{subindent}{file} ({size_mb:.2f} MB)")
        
        return downloaded_path
        
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {str(e)}")
        return None

def download_specific_files(model_id: str, filenames: list, local_dir: str = None, token: str = None):
    """
    ä¸‹è½½æ¨¡å‹çš„ç‰¹å®šæ–‡ä»¶
    
    å‚æ•°:
        model_id (str): æ¨¡å‹ID
        filenames (list): è¦ä¸‹è½½çš„æ–‡ä»¶ååˆ—è¡¨
        local_dir (str): æœ¬åœ°ä¿å­˜ç›®å½•
        token (str): Hugging Faceè®¿é—®ä»¤ç‰Œ
    """
    
    if local_dir is None:
        model_name = model_id.split('/')[-1]
        local_dir = f"./models/{model_name}"
    
    Path(local_dir).mkdir(parents=True, exist_ok=True)
    
    print(f"å¼€å§‹ä¸‹è½½ç‰¹å®šæ–‡ä»¶: {model_id}")
    print(f"æ–‡ä»¶åˆ—è¡¨: {filenames}")
    
    downloaded_files = []
    
    for filename in filenames:
        try:
            print(f"æ­£åœ¨ä¸‹è½½: {filename}")
            file_path = hf_hub_download(
                repo_id=model_id,
                filename=filename,
                local_dir=local_dir,
                token=token,
                resume_download=True
            )
            downloaded_files.append(file_path)
            print(f"âœ… {filename} ä¸‹è½½å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ {filename} ä¸‹è½½å¤±è´¥: {str(e)}")
    
    return downloaded_files

# ç¤ºä¾‹è°ƒç”¨



def download():
    """ä¸»å‡½æ•°"""
    
    # ç›®æ ‡æ¨¡å‹é…ç½®
    # MODEL_ID = "lmms-lab/llava-onevision-qwen2-0.5b-ov"
    MODEL_ID = "lmms-lab/llava-onevision-qwen2-7b-ov"
    
    print("ğŸ¤— Hugging Faceæ¨¡å‹ä¸‹è½½å·¥å…·")
    print("=" * 50)
    
    # é€‰æ‹©ä¸‹è½½æ¨¡å¼
    # print("è¯·é€‰æ‹©ä¸‹è½½æ¨¡å¼:")
    # print("1. ä¸‹è½½å®Œæ•´æ¨¡å‹ (æ¨è)")
    # print("2. ä»…ä¸‹è½½æƒé‡æ–‡ä»¶")
    # print("3. è‡ªå®šä¹‰æ–‡ä»¶ä¸‹è½½")
    
    # choice = input("è¯·è¾“å…¥é€‰æ‹© (1-3): ").strip()
    choice = "1"  # é»˜è®¤é€‰æ‹©ä¸‹è½½å®Œæ•´æ¨¡å‹
    
    # # è·å–è®¿é—®ä»¤ç‰Œï¼ˆå¯é€‰ï¼‰
    # token = input("è¯·è¾“å…¥Hugging Face Token (å¯é€‰ï¼Œç›´æ¥å›è½¦è·³è¿‡): ").strip()
    # if not token:
    #     token = None
    token = None
    # è·å–ä¿å­˜è·¯å¾„
    # save_dir = input(f"è¯·è¾“å…¥ä¿å­˜è·¯å¾„ (é»˜è®¤: ./models/llava-onevision-qwen2-0.5b-ov): ").strip()
    # save_dir = '/mnt/sda/shenhao/models/llava-onevision-qwen2-0.5b-ov'  # é»˜è®¤ä¿å­˜è·¯å¾„
    save_dir = '/mnt/sda/shenhao/models/llava-onevision-qwen2-7b-ov'  # é»˜è®¤ä¿å­˜è·¯å¾„
    if not save_dir:
        save_dir = None
    
    if choice == "1":
        # ä¸‹è½½å®Œæ•´æ¨¡å‹
        download_model_weights(
            model_id=MODEL_ID,
            local_dir=save_dir,
            token=token
        )
        
    elif choice == "2":
        # ä»…ä¸‹è½½æƒé‡æ–‡ä»¶
        download_model_weights(
            model_id=MODEL_ID,
            local_dir=save_dir,
            token=token,
            allow_patterns=["*.bin", "*.safetensors", "*.pt", "*.pth", "config.json", "tokenizer*"]
        )
        
    elif choice == "3":
        # è‡ªå®šä¹‰æ–‡ä»¶ä¸‹è½½
        print("å¸¸è§æ–‡ä»¶ç±»å‹:")
        print("- *.safetensors (æ¨èçš„æƒé‡æ ¼å¼)")
        print("- *.bin (PyTorchæƒé‡æ–‡ä»¶)")
        print("- config.json (æ¨¡å‹é…ç½®)")
        print("- tokenizer.json, tokenizer_config.json (åˆ†è¯å™¨)")
        
        files_input = input("è¯·è¾“å…¥è¦ä¸‹è½½çš„æ–‡ä»¶åï¼Œç”¨é€—å·åˆ†éš”: ").strip()
        if files_input:
            filenames = [f.strip() for f in files_input.split(',')]
            download_specific_files(
                model_id=MODEL_ID,
                filenames=filenames,
                local_dir=save_dir,
                token=token
            )
        else:
            print("âŒ æœªæŒ‡å®šæ–‡ä»¶å")
    
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")

if __name__ == "__main__":
    os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
    download()


# if __name__ == "__main__":
#     url = "https://hf-mirror.com/datasets/zhuomingliu/PAVEDataset/blob/main/MUSIC-AVQA-videos-Real_audio_imagebind_feat.zip"
#     save_path = "/mnt/sda/shenhao/datasets/PAVE/MUSIC-AVQA-videos-Real_audio_imagebind_feat.zip"
#     download_file_from_hf(url, save_path)

# if __name__ == "__main__":
#     # ä¸‹è½½ç‰¹å®šçš„ZIPæ–‡ä»¶
#     download_specific_file(
#         repo_id="zhuomingliu/PAVEDataset",
#         filename="MUSIC-AVQA-videos-Real_audio_imagebind_feat.zip",
#         save_path="/mnt/sda/shenhao/datasets/PAVE/"
#     )